{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Sigma Data Challenge - NYC MTA Turnstile Usage Dataset Analysis by Andy Chen\n",
    "\n",
    "Have a look at / download the following dataset :\n",
    "- Go to http://web.mta.info/developers/turnstile.html\n",
    "\n",
    "- This dataset shows entry & exit counter values for each turnstile-device in each station in the NYC Subway System.\n",
    "\n",
    "- Note these aren’t counts per interval, but equivalent to an “odometer” reading for each device.\n",
    "*You will be evaluated in terms of coding, data analysis, and visualization skills.\n",
    "\n",
    "Data analysis:\n",
    "- Which station has the most number of units?\n",
    "\n",
    "- What is the total number of entries & exits across the subway system for February 1, 2013?\n",
    "\n",
    "- Let’s define the busy-ness as sum of entry & exit count. What station was the busiest on February 1, 2013? What turnstile was the busiest on that date?\n",
    "\n",
    "- What stations have seen the most usage growth/decline in 2013?\n",
    "\n",
    "- What dates are the least busy? Could you identify days on which stations were not operating at full capacity or closed entirely?\n",
    "\n",
    "- Bonus:  What hour is the busiest for station CANAL ST in Q1 2013?\n",
    "\n",
    "Visualization:\n",
    "- Plot the daily row counts for data files in Q1 2013.\n",
    "\n",
    "- Plot the daily total number of entries & exits across the system for Q1 2013.\n",
    "\n",
    "- Plot the mean and standard deviation of the daily total number of entries & exits for each month in Q1 2013 for station 34 ST-PENN STA.\n",
    "\n",
    "- Plot 25/50/75 percentile of the daily total number of entries & exits for each month in Q1 2013 for station 34 ST-PENN STA.\n",
    "\n",
    "- Plot the daily number of closed stations and number of stations that were not operating at full capacity in Q1 2013."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Which Station has the most number of units?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Answer: Station: 86 ST and CANAL ST\n",
    "\n",
    "First, I need to groupby 'STATION' and count unique values in 'UNIT'. Then, I sort them and find the max one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Station  unit_count\n",
      "114            86 ST           5\n",
      "175         CANAL ST           5\n",
      "73   42 ST-GRD CNTRL           4\n",
      "68    34 ST-PENN STA           4\n",
      "231        FULTON ST           4\n",
      "11            125 ST           4\n",
      "338     PROSPECT AVE           3\n",
      "91             59 ST           3\n",
      "269    KINGS HIGHWAY           3\n",
      "84             50 ST           3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_unit=pd.read_excel('http://web.mta.info/developers/resources/nyct/turnstile/Remote-Booth-Station.xls')\n",
    "print(df_unit.groupby('Station').Remote.nunique().reset_index(name='unit_count').sort_values(['unit_count'],ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2.What is the total number of entries & exits across the subway system for February 1, 2013?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Answer: num_entries: 90830543, num_exit: 9.565364e+06\n",
    "\n",
    "First I got the Data_File: 'Saturday, February 02, 2013' and I found it actually has 43 columns as following:\n",
    "['C/A','UNIT','SCP','DATE1','TIME1','DESC1','ENTRIES1','EXITS1'\n",
    "                   ,'DATE2','TIME2','DESC2','ENTRIES2','EXITS2'\n",
    "                   ,'DATE3','TIME3','DESC3','ENTRIES3','EXITS3'\n",
    "                   ,'DATE4','TIME4','DESC4','ENTRIES4','EXITS4'\n",
    "                   ,'DATE5','TIME5','DESC5','ENTRIES5','EXITS5'\n",
    "                   ,'DATE6','TIME6','DESC6','ENTRIES6','EXITS6'\n",
    "                   ,'DATE7','TIME7','DESC7','ENTRIES7','EXITS7'\n",
    "                   ,'DATE8','TIME8','DESC8','ENTRIES8','EXITS8']\n",
    "                   \n",
    "Field Description:\n",
    "C/A = Control Area (A002)\n",
    "UNIT = Remote Unit for a station (R051)\n",
    "SCP = Subunit Channel Position represents an specific address for a device (02-00-00)\n",
    "DATEn = Represents the date (MM-DD-YY)\n",
    "TIMEn = Represents the time (hh:mm:ss) for a scheduled audit event\n",
    "DEScn = Represent the \"REGULAR\" scheduled audit event (occurs every 4 hours)\n",
    "ENTRIESn = The comulative entry register value for a device\n",
    "EXISTn = The cumulative exit register value for a device\n",
    "\n",
    "So, I'd like to format it as following:\n",
    "['C/A','UNIT','SCP','DATE','TIME','DESC','ENTRIES','EXITS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    C/A  UNIT       SCP      DATE      TIME     DESC    ENTRIES      EXITS\n",
      "0  A002  R051  02-00-00  01-26-13  03:00:00  REGULAR  3967032.0  1367372.0\n",
      "0  A002  R051  02-00-00  01-26-13  07:00:00  REGULAR  3967043.0  1367381.0\n",
      "0  A002  R051  02-00-00  01-26-13  11:00:00  REGULAR  3967096.0  1367435.0\n",
      "0  A002  R051  02-00-00  01-26-13  15:00:00  REGULAR  3967238.0  1367452.0\n",
      "0  A002  R051  02-00-00  01-26-13  19:00:00  REGULAR  3967547.0  1367468.0\n",
      "0  A002  R051  02-00-00  01-26-13  23:00:00  REGULAR  3967718.0  1367490.0\n",
      "0  A002  R051  02-00-00  01-27-13  03:00:00  REGULAR  3967766.0  1367509.0\n",
      "0  A002  R051  02-00-00  01-27-13  07:00:00  REGULAR  3967778.0  1367515.0\n",
      "1  A002  R051  02-00-00  01-27-13  11:00:00  REGULAR  3967826.0  1367578.0\n",
      "1  A002  R051  02-00-00  01-27-13  15:00:00  REGULAR  3967988.0  1367633.0\n",
      "1  A002  R051  02-00-00  01-27-13  19:00:00  REGULAR  3968260.0  1367679.0\n",
      "1  A002  R051  02-00-00  01-27-13  23:00:00  REGULAR  3968390.0  1367717.0\n",
      "1  A002  R051  02-00-00  01-28-13  03:00:00  REGULAR  3968423.0  1367720.0\n",
      "1  A002  R051  02-00-00  01-28-13  07:00:00  REGULAR  3968438.0  1367758.0\n",
      "1  A002  R051  02-00-00  01-28-13  11:00:00  REGULAR  3968601.0  1368084.0\n",
      "1  A002  R051  02-00-00  01-28-13  15:00:00  REGULAR  3968798.0  1368165.0\n",
      "2  A002  R051  02-00-00  01-28-13  19:00:00  REGULAR  3969685.0  1368236.0\n",
      "2  A002  R051  02-00-00  01-28-13  23:00:00  REGULAR  3969945.0  1368263.0\n",
      "2  A002  R051  02-00-00  01-29-13  03:00:00  REGULAR  3969947.0  1368267.0\n",
      "2  A002  R051  02-00-00  01-29-13  07:00:00  REGULAR  3969963.0  1368298.0\n",
      "2  A002  R051  02-00-00  01-29-13  11:00:00  REGULAR  3970112.0  1368639.0\n",
      "2  A002  R051  02-00-00  01-29-13  15:00:00  REGULAR  3970314.0  1368705.0\n",
      "2  A002  R051  02-00-00  01-29-13  19:00:00  REGULAR  3971170.0  1368796.0\n",
      "2  A002  R051  02-00-00  01-29-13  23:00:00  REGULAR  3971424.0  1368820.0\n",
      "3  A002  R051  02-00-00  01-30-13  03:00:00  REGULAR  3971424.0  1368820.0\n",
      "3  A002  R051  02-00-00  01-30-13  07:00:00  REGULAR  3971442.0  1368857.0\n",
      "3  A002  R051  02-00-00  01-30-13  11:00:00  REGULAR  3971586.0  1369179.0\n",
      "3  A002  R051  02-00-00  01-30-13  15:00:00  REGULAR  3971785.0  1369271.0\n",
      "3  A002  R051  02-00-00  01-30-13  19:00:00  REGULAR  3972644.0  1369349.0\n",
      "3  A002  R051  02-00-00  01-30-13  23:00:00  REGULAR  3972902.0  1369398.0\n",
      "3  A002  R051  02-00-00  01-31-13  03:00:00  REGULAR  3972902.0  1369398.0\n",
      "3  A002  R051  02-00-00  01-31-13  07:00:00  REGULAR  3972920.0  1369435.0\n",
      "4  A002  R051  02-00-00  01-31-13  11:00:00  REGULAR  3973086.0  1369749.0\n",
      "4  A002  R051  02-00-00  01-31-13  14:43:33  REGULAR  3973280.0  1369836.0\n",
      "4  A002  R051  02-00-00  01-31-13  15:00:00  REGULAR  3973287.0  1369836.0\n",
      "4  A002  R051  02-00-00  01-31-13  19:00:00  REGULAR  3974210.0  1369915.0\n",
      "4  A002  R051  02-00-00  01-31-13  23:00:00  REGULAR  3974506.0  1369951.0\n",
      "4  A002  R051  02-00-00  02-01-13  03:00:00  REGULAR  3974506.0  1369951.0\n",
      "4  A002  R051  02-00-00  02-01-13  07:00:00  REGULAR  3974518.0  1369972.0\n",
      "4  A002  R051  02-00-00  02-01-13  11:00:00  REGULAR  3974706.0  1370294.0\n",
      "5  A002  R051  02-00-00  02-01-13  15:00:00  REGULAR  3974913.0  1370326.0\n",
      "5  A002  R051  02-00-00  02-01-13  19:00:00  REGULAR  3975747.0  1370378.0\n",
      "5  A002  R051  02-00-00  02-01-13  23:00:00  REGULAR  3976035.0  1370406.0\n",
      "6  A002  R051  02-00-01  01-26-13  03:00:00  REGULAR  3786259.0   819749.0\n",
      "6  A002  R051  02-00-01  01-26-13  07:00:00  REGULAR  3786265.0   819757.0\n",
      "6  A002  R051  02-00-01  01-26-13  11:00:00  REGULAR  3786302.0   819786.0\n",
      "6  A002  R051  02-00-01  01-26-13  15:00:00  REGULAR  3786473.0   819796.0\n",
      "6  A002  R051  02-00-01  01-26-13  19:00:00  REGULAR  3786736.0   819813.0\n",
      "6  A002  R051  02-00-01  01-26-13  23:00:00  REGULAR  3786870.0   819829.0\n",
      "6  A002  R051  02-00-01  01-27-13  03:00:00  REGULAR  3786911.0   819834.0\n",
      "         C/A  UNIT       SCP      DATE      TIME        DESC  ENTRIES  EXITS\n",
      "30854  TRAM2  R469  00-05-00  02-01-13  20:00:00     REGULAR    922.0   62.0\n",
      "30855  TRAM2  R469  00-05-01  01-26-13  00:00:00     REGULAR   5554.0   99.0\n",
      "30855  TRAM2  R469  00-05-01  01-26-13  04:00:00     REGULAR   5554.0   99.0\n",
      "30855  TRAM2  R469  00-05-01  01-26-13  08:00:00     REGULAR   5554.0   99.0\n",
      "30855  TRAM2  R469  00-05-01  01-26-13  12:00:00     REGULAR   5554.0   99.0\n",
      "30855  TRAM2  R469  00-05-01  01-26-13  16:00:00     REGULAR   5554.0   99.0\n",
      "30855  TRAM2  R469  00-05-01  01-26-13  20:00:00     REGULAR   5554.0   99.0\n",
      "30855  TRAM2  R469  00-05-01  01-27-13  00:00:00     REGULAR   5554.0   99.0\n",
      "30855  TRAM2  R469  00-05-01  01-27-13  04:00:00     REGULAR   5554.0   99.0\n",
      "30856  TRAM2  R469  00-05-01  01-27-13  08:00:00     REGULAR   5554.0   99.0\n",
      "30856  TRAM2  R469  00-05-01  01-27-13  12:00:00     REGULAR   5554.0   99.0\n",
      "30856  TRAM2  R469  00-05-01  01-27-13  16:00:00     REGULAR   5554.0   99.0\n",
      "30856  TRAM2  R469  00-05-01  01-27-13  20:00:00     REGULAR   5554.0   99.0\n",
      "30856  TRAM2  R469  00-05-01  01-28-13  00:00:00     REGULAR   5554.0   99.0\n",
      "30856  TRAM2  R469  00-05-01  01-28-13  04:00:00     REGULAR   5554.0   99.0\n",
      "30856  TRAM2  R469  00-05-01  01-28-13  08:00:00     REGULAR   5554.0   99.0\n",
      "30856  TRAM2  R469  00-05-01  01-28-13  12:00:00     REGULAR   5554.0   99.0\n",
      "30857  TRAM2  R469  00-05-01  01-28-13  16:00:00     REGULAR   5554.0   99.0\n",
      "30857  TRAM2  R469  00-05-01  01-28-13  20:00:00     REGULAR   5554.0   99.0\n",
      "30857  TRAM2  R469  00-05-01  01-29-13  00:00:00     REGULAR   5554.0   99.0\n",
      "30857  TRAM2  R469  00-05-01  01-29-13  04:00:00     REGULAR   5554.0   99.0\n",
      "30857  TRAM2  R469  00-05-01  01-29-13  08:00:00     REGULAR   5554.0   99.0\n",
      "30857  TRAM2  R469  00-05-01  01-29-13  12:00:00     REGULAR   5554.0   99.0\n",
      "30857  TRAM2  R469  00-05-01  01-29-13  16:00:00     REGULAR   5554.0   99.0\n",
      "30857  TRAM2  R469  00-05-01  01-29-13  20:00:00     REGULAR   5554.0   99.0\n",
      "30858  TRAM2  R469  00-05-01  01-30-13  00:00:00     REGULAR   5554.0   99.0\n",
      "30858  TRAM2  R469  00-05-01  01-30-13  04:00:00     REGULAR   5554.0   99.0\n",
      "30858  TRAM2  R469  00-05-01  01-30-13  04:00:00  RECOVR AUD   5554.0   99.0\n",
      "30858  TRAM2  R469  00-05-01  01-30-13  04:09:19   DOOR OPEN   5554.0   99.0\n",
      "30858  TRAM2  R469  00-05-01  01-30-13  04:16:14  DOOR CLOSE   5554.0  100.0\n",
      "30858  TRAM2  R469  00-05-01  01-30-13  04:16:21   DOOR OPEN   5554.0  100.0\n",
      "30858  TRAM2  R469  00-05-01  01-30-13  04:16:46  DOOR CLOSE   5554.0  100.0\n",
      "30858  TRAM2  R469  00-05-01  01-30-13  07:48:11     REGULAR   5554.0  100.0\n",
      "30859  TRAM2  R469  00-05-01  01-30-13  08:00:00     REGULAR   5554.0  100.0\n",
      "30859  TRAM2  R469  00-05-01  01-30-13  12:00:00     REGULAR   5554.0  100.0\n",
      "30859  TRAM2  R469  00-05-01  01-30-13  16:00:00     REGULAR   5554.0  100.0\n",
      "30859  TRAM2  R469  00-05-01  01-30-13  20:00:00     REGULAR   5554.0  100.0\n",
      "30859  TRAM2  R469  00-05-01  01-31-13  00:00:00     REGULAR   5554.0  100.0\n",
      "30859  TRAM2  R469  00-05-01  01-31-13  04:00:00     REGULAR   5554.0  100.0\n",
      "30859  TRAM2  R469  00-05-01  01-31-13  04:00:00  RECOVR AUD   5554.0  100.0\n",
      "30859  TRAM2  R469  00-05-01  01-31-13  08:00:00     REGULAR   5554.0  100.0\n",
      "30860  TRAM2  R469  00-05-01  01-31-13  12:00:00     REGULAR   5554.0  100.0\n",
      "30860  TRAM2  R469  00-05-01  01-31-13  16:00:00     REGULAR   5554.0  100.0\n",
      "30860  TRAM2  R469  00-05-01  01-31-13  20:00:00     REGULAR   5554.0  100.0\n",
      "30860  TRAM2  R469  00-05-01  02-01-13  00:00:00     REGULAR   5554.0  100.0\n",
      "30860  TRAM2  R469  00-05-01  02-01-13  04:00:00     REGULAR   5554.0  100.0\n",
      "30860  TRAM2  R469  00-05-01  02-01-13  08:00:00     REGULAR   5554.0  100.0\n",
      "30860  TRAM2  R469  00-05-01  02-01-13  12:00:00     REGULAR   5554.0  100.0\n",
      "30860  TRAM2  R469  00-05-01  02-01-13  16:00:00     REGULAR   5554.0  100.0\n",
      "30861  TRAM2  R469  00-05-01  02-01-13  20:00:00     REGULAR   5554.0  100.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df130202=pd.read_csv('http://web.mta.info/developers/data/nyct/turnstile/turnstile_130202.txt', header=None)\n",
    "\n",
    "df130202.columns=['C/A','UNIT','SCP','DATE1','TIME1','DESC1','ENTRIES1','EXITS1'\n",
    "                                    ,'DATE2','TIME2','DESC2','ENTRIES2','EXITS2'\n",
    "                                    ,'DATE3','TIME3','DESC3','ENTRIES3','EXITS3'\n",
    "                                    ,'DATE4','TIME4','DESC4','ENTRIES4','EXITS4'\n",
    "                                    ,'DATE5','TIME5','DESC5','ENTRIES5','EXITS5'\n",
    "                                    ,'DATE6','TIME6','DESC6','ENTRIES6','EXITS6'\n",
    "                                    ,'DATE7','TIME7','DESC7','ENTRIES7','EXITS7'\n",
    "                                    ,'DATE8','TIME8','DESC8','ENTRIES8','EXITS8']\n",
    "\n",
    "df1=df130202[['C/A','UNIT','SCP','DATE1','TIME1','DESC1','ENTRIES1','EXITS1']]\n",
    "df2=df130202[['C/A','UNIT','SCP','DATE2','TIME2','DESC2','ENTRIES2','EXITS2']]\n",
    "df3=df130202[['C/A','UNIT','SCP','DATE3','TIME3','DESC3','ENTRIES3','EXITS3']]\n",
    "df4=df130202[['C/A','UNIT','SCP','DATE4','TIME4','DESC4','ENTRIES4','EXITS4']]\n",
    "df5=df130202[['C/A','UNIT','SCP','DATE5','TIME5','DESC5','ENTRIES5','EXITS5']]\n",
    "df6=df130202[['C/A','UNIT','SCP','DATE6','TIME6','DESC6','ENTRIES6','EXITS6']]\n",
    "df7=df130202[['C/A','UNIT','SCP','DATE7','TIME7','DESC7','ENTRIES7','EXITS7']]\n",
    "df8=df130202[['C/A','UNIT','SCP','DATE8','TIME8','DESC8','ENTRIES8','EXITS8']]\n",
    "\n",
    "df1.columns=['C/A','UNIT','SCP','DATE','TIME','DESC','ENTRIES','EXITS']\n",
    "df2.columns=['C/A','UNIT','SCP','DATE','TIME','DESC','ENTRIES','EXITS']\n",
    "df3.columns=['C/A','UNIT','SCP','DATE','TIME','DESC','ENTRIES','EXITS']\n",
    "df4.columns=['C/A','UNIT','SCP','DATE','TIME','DESC','ENTRIES','EXITS']\n",
    "df5.columns=['C/A','UNIT','SCP','DATE','TIME','DESC','ENTRIES','EXITS']\n",
    "df6.columns=['C/A','UNIT','SCP','DATE','TIME','DESC','ENTRIES','EXITS']\n",
    "df7.columns=['C/A','UNIT','SCP','DATE','TIME','DESC','ENTRIES','EXITS']\n",
    "df8.columns=['C/A','UNIT','SCP','DATE','TIME','DESC','ENTRIES','EXITS']\n",
    "\n",
    "df130202rs=df1.append(df2)\n",
    "df130202rs=df130202rs.append(df3)\n",
    "df130202rs=df130202rs.append(df4)\n",
    "df130202rs=df130202rs.append(df5)\n",
    "df130202rs=df130202rs.append(df6)\n",
    "df130202rs=df130202rs.append(df7)\n",
    "df130202rs=df130202rs.append(df8)\n",
    "\n",
    "#Now we can format our data as below:\n",
    "df=df130202rs.sort_values(['C/A','UNIT','SCP','DATE','TIME']).dropna()\n",
    "print(df.head(50))\n",
    "print(df.tail(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ENTRIES         EXITS\n",
      "DATE                               \n",
      "01-26-13    9299906.0  3.658605e+06\n",
      "01-27-13    9810169.0  8.205277e+06\n",
      "01-28-13    5162636.0  1.982119e+07\n",
      "01-29-13   56099709.0  2.131601e+07\n",
      "01-30-13    5722425.0  4.364807e+06\n",
      "01-31-13  823381784.0  1.061253e+09\n",
      "02-01-13   90830543.0  9.565364e+06\n"
     ]
    }
   ],
   "source": [
    "a=df.groupby(['C/A','UNIT','SCP','DATE'])['ENTRIES','EXITS'].min()\n",
    "b=df.groupby(['C/A','UNIT','SCP','DATE'])['ENTRIES','EXITS'].max()\n",
    "c=b-a\n",
    "d=c.groupby('DATE')[['ENTRIES','EXITS']].sum()\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3.Let’s define the busy-ness as sum of entry & exit count. What station was the busiest on February 1, 2013? What turnstile was the busiest on that date?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Answer:Station:BEDFORD/NOSTRAN was the busiest on Feb1 and Turnstile(UNIT):269 was the busiest on that date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    ENTRIES      EXITS    BUSYNESS\n",
      "STATION                                           \n",
      "BEDFORD/NOSTRAN  80911845.0  3010149.0  83921994.0\n",
      "JOURNAL SQUARE    4453899.0  2371677.0   6825576.0\n",
      "34 ST-PENN STA     173953.0   160065.0    334018.0\n",
      "42 ST-GRD CNTRL    157337.0   154075.0    311412.0\n",
      "34 ST-HERALD SQ    115738.0   101705.0    217443.0\n",
      "         ENTRIES      EXITS    BUSYNESS\n",
      "UNIT                                   \n",
      "R269  80911845.0  3010149.0  83921994.0\n",
      "R552   4453899.0  2371677.0   6825576.0\n",
      "R170     89637.0    90554.0    180191.0\n",
      "R046     78900.0    72773.0    151673.0\n",
      "R020     63287.0    64097.0    127384.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_key = pd.read_excel('http://web.mta.info/developers/resources/nyct/turnstile/Remote-Booth-Station.xls')\n",
    "df_key.columns=['UNIT', 'C/A', 'STATION', 'LINE','DIVISION']\n",
    "e = pd.merge(df,df_key,on=['UNIT','C/A'],how = 'left')\n",
    "f=e[['DATE','TIME','STATION','UNIT','SCP','ENTRIES','EXITS']].set_index('DATE')\n",
    "g=f.loc['02-01-13']\n",
    "h=g.groupby(['STATION','UNIT','SCP'])['ENTRIES','EXITS'].min()\n",
    "i=g.groupby(['STATION','UNIT','SCP'])['ENTRIES','EXITS'].max()\n",
    "j=i-h\n",
    "j['BUSYNESS']=j['ENTRIES']+j['EXITS']\n",
    "k=j.groupby('STATION').sum()\n",
    "l=k.sort_values(['BUSYNESS'],ascending=False).head(5)\n",
    "print(l)\n",
    "m=j.groupby('UNIT').sum()\n",
    "n=m.sort_values(['BUSYNESS'],ascending=False).head(5)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4.What stations have seen the most usage growth/decline in 2013?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
